{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_rules_chomsky = {\n",
    "\n",
    "    \"S\": [\n",
    "        [\"NP\", \"VP\"],  # Declarative\n",
    "\n",
    "        # Declarative Negation Rules\n",
    "        [\"X7\", \"VP\"],  # Declarative with negation\n",
    "\n",
    "        # VP : Imperative\n",
    "        [\"VB\"],  # Base form verb  [\"VB\"]\n",
    "        [\"VBD\"],  # Past tense verb [\"VBD\"]\n",
    "        [\"VBZ\", \"NP\"],  # 3rd person singular present verb + NP\n",
    "        [\"VBP\", \"NP\"],  # Non-3rd person singular present verb + NP\n",
    "        [\"VBD\", \"NP\"],  # Past tense verb + NP\n",
    "        [\"X1\", \"PP\"],  # Base form verb + NP + PP\n",
    "        [\"VP\", \"PP\"],  # VP + PP\n",
    "        # Imperative sentence rule:\n",
    "        [\"VB\", \"NP\"],\n",
    "        [\"AUX\", \"VBG\"],\n",
    "        \n",
    "        # Imperative Negation Rules\n",
    "        [\"X8\", \"VB\"],\n",
    "\n",
    "        # Questions\n",
    "        [\"X4\", \"VP\"],  # Yes/No Question: Modal verb + NP + VP\n",
    "        [\"X3\", \"X2\"]  # Wh-Question: Wh-word + Modal verb + NP + VP\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"NP\": [\n",
    "        [\"PRP\"],  # Pronoun  [\"PRP\"]\n",
    "        [\"NNP\"],  # Singular Proper Noun [\"NNP\"]\n",
    "        [\"DT\", \"Nominal\"],  # Determiner + Nominal\n",
    "        [\"DT\", \"NN\"]\n",
    "    ],\n",
    "\n",
    "    \"Nominal\": [\n",
    "        [\"NN\"],  # Singular Noun [\"NN\"]\n",
    "        [\"NNS\"],  # Plural Noun   [\"NNS\"]\n",
    "        [\"Nominal\", \"NN\"],  # Nominal + Singular Noun\n",
    "        [\"Nominal\", \"PP\"],  # Nominal + Prepositional Phrase\n",
    "        [\"JJ\", \"Nominal\"],  # Base Adjective + Nominal\n",
    "        [\"JJR\", \"Nominal\"],  # Comparative Adjective + Nominal\n",
    "        [\"JJS\", \"Nominal\"],  # Superlative Adjective + Nominal\n",
    "        \"VBG\",  # Gerund as Nominal\n",
    "    ],\n",
    "\n",
    "    \"VP\": [\n",
    "        # Declarative sentence rule:\n",
    "        [\"VB\"],  # Base form verb  [\"VB\"]\n",
    "        [\"VBD\"],  # Past tense verb [\"VBD\"]\n",
    "        [\"VBZ\", \"NP\"],  # 3rd person singular present verb + NP\n",
    "        [\"VBP\", \"NP\"],  # Non-3rd person singular present verb + NP\n",
    "        [\"VBD\", \"NP\"],  # Past tense verb + NP\n",
    "        [\"X1\", \"PP\"],  # Base form verb + NP + PP\n",
    "        [\"VP\", \"PP\"],  # VP + PP\n",
    "        # Imperative sentence rule:\n",
    "        [\"VB\", \"NP\"],\n",
    "        [\"AUX\", \"VBG\"],\n",
    "    ],\n",
    "\n",
    "    \"X1\": [\n",
    "        [\"VB\", \"NP\"],\n",
    "    ],\n",
    "\n",
    "    \"X2\": [\n",
    "        [\"NP\", \"VP\"],\n",
    "    ],\n",
    "\n",
    "    \"X3\": [\n",
    "        [\"Wh_Word\", \"MD\"],\n",
    "    ],\n",
    "\n",
    "    \"X4\": [\n",
    "        [\"MD\", \"NP\"],\n",
    "    ],\n",
    "\n",
    "    \"X5\": [\n",
    "        [\"AUX\", \"Neg\"]\n",
    "    ],\n",
    "\n",
    "    \"X6\": [\n",
    "        [\"MD\", \"Neg\"]\n",
    "    ],\n",
    "\n",
    "    \"X7\": [\n",
    "        [\"NP\", \"X5\"],\n",
    "        [\"NP\", \"X6\"],\n",
    "    ],\n",
    "\n",
    "    \"X8\": [\n",
    "        [\"DO\", \"Neg\"]\n",
    "    ],\n",
    "\n",
    "    \"PP\": [\n",
    "        [\"IN\", \"NP\"],  # Preposition + NP\n",
    "    ],\n",
    "\n",
    "    \"DT\": [\n",
    "        [\"that\"], [\"this\"], [\"a\"], [\"the\"], [\"an\"], [\"these\"], [\"those\"]\n",
    "    ],\n",
    "\n",
    "    \"NN\": [\n",
    "        [\"book\"], [\"flight\"], [\"meal\"], [\"money\"], [\"present\"], [\"school\"], [\"music\"], [\"movie\"],\n",
    "        [\"friend\"], [\"apple\"], [\"face\"], [\"market\"], [\"dog\"], [\"cat\"], [\"house\"], [\"car\"], [\"teacher\"],\n",
    "        [\"child\"], [\"idea\"], [\"story\"], [\"game\"], [\"photo\"], [\"river\"], [\"city\"], [\"garden\"], [\"song\"],\n",
    "        [\"phone\"], [\"computer\"], [\"table\"], [\"bottle\"], [\"shirt\"], [\"painting\"], [\"mother\"], [\"dinner\"],\n",
    "        [\"culture\"], [\"history\"], [\"watermelon\"], [\"fruit\"], [\"moonlight\"], [\"tree\"], [\"village\"], [\"listen\"]\n",
    "    ],\n",
    "    \"NNS\": [\n",
    "        [\"novels\"], [\"friends\"], [\"flights\"], [\"schools\"], [\"presents\"], [\"meals\"], [\"books\"],\n",
    "        [\"apples\"], [\"faces\"], [\"dogs\"], [\"cats\"], [\"houses\"], [\"cars\"], [\"teachers\"], [\"children\"],\n",
    "        [\"ideas\"], [\"stories\"], [\"games\"], [\"photos\"], [\"rivers\"], [\"cities\"], [\"gardens\"], [\"songs\"],\n",
    "        [\"phones\"], [\"computers\"], [\"tables\"], [\"bottles\"], [\"shirts\"]\n",
    "    ],\n",
    "    \"VB\": [\n",
    "        [\"prefer\"], [\"include\"], [\"eat\"], [\"take\"], [\"want\"], [\"watch\"], [\"spend\"], [\"enjoy\"], [\"book\"],\n",
    "        [\"present\"], [\"build\"], [\"sing\"], [\"dance\"], [\"paint\"], [\"write\"], [\"call\"], [\"drive\"], [\"buy\"],\n",
    "        [\"sell\"], [\"read\"], [\"open\"], [\"close\"], [\"fix\"], [\"carry\"], [\"create\"], [\"explore\"], [\"face\"],\n",
    "        [\"book\"], [\"come\"], [\"tell\"], [\"attend\"], [\"summer\"]\n",
    "    ],\n",
    "    \"VBD\": [\n",
    "        [\"bought\"], [\"helped\"], [\"watched\"], [\"ate\"], [\"took\"], [\"spent\"], [\"enjoyed\"], [\"booked\"],\n",
    "        [\"presented\"], [\"went\"], [\"was\"], [\"were\"], [\"built\"], [\"sang\"], [\"danced\"], [\"painted\"],\n",
    "        [\"wrote\"], [\"called\"], [\"drove\"], [\"sold\"], [\"read\"], [\"opened\"], [\"closed\"], [\"fixed\"],\n",
    "        [\"carried\"], [\"created\"], [\"explored\"], [\"faced\"], [\"booked\"]\n",
    "    ],\n",
    "    \"VBZ\": [\n",
    "        [\"prefers\"], [\"includes\"], [\"eats\"], [\"takes\"], [\"spends\"], [\"watches\"], [\"enjoys\"], [\"books\"],\n",
    "        [\"presents\"], [\"goes\"], [\"builds\"], [\"sings\"], [\"dances\"], [\"paints\"], [\"writes\"], [\"calls\"],\n",
    "        [\"drives\"], [\"buys\"], [\"sells\"], [\"reads\"], [\"opens\"], [\"closes\"], [\"fixes\"], [\"carries\"],\n",
    "        [\"creates\"], [\"explores\"], [\"faces\"], [\"books\"]\n",
    "    ],\n",
    "    \"VBP\": [\n",
    "        [\"prefer\"], [\"include\"], [\"eat\"], [\"take\"], [\"spend\"], [\"watch\"], [\"enjoy\"], [\"book\"],\n",
    "        [\"present\"], [\"build\"], [\"sing\"], [\"dance\"], [\"paint\"], [\"write\"], [\"call\"], [\"drive\"],\n",
    "        [\"buy\"], [\"sell\"], [\"read\"], [\"open\"], [\"close\"], [\"fix\"], [\"carry\"], [\"create\"], [\"explore\"],\n",
    "        [\"face\"]\n",
    "    ],\n",
    "    \"PRP\": [[\"I\"], [\"i\"], [\"she\"], [\"we\"], [\"you\"], [\"her\"], [\"he\"], [\"it\"], [\"they\"], [\"them\"]],\n",
    "    \"NNP\": [[\"Houston\"], [\"NWA\"]],\n",
    "    \"IN\": [\n",
    "        [\"from\"], [\"to\"], [\"on\"], [\"near\"], [\"through\"], [\"with\"], [\"under\"], [\"over\"], [\"beside\"],\n",
    "        [\"between\"], [\"before\"], [\"after\"], [\"inside\"], [\"outside\"], [\"around\"], [\"above\"], [\"below\"],\n",
    "        [\"in\"], [\"for\"], [\"of\"]\n",
    "    ],\n",
    "    \"RB\": [\n",
    "        [\"quickly\"], [\"slowly\"], [\"often\"], [\"always\"], [\"never\"], [\"here\"], [\"yesterday\"],\n",
    "        [\"today\"], [\"tomorrow\"], [\"carefully\"], [\"happily\"], [\"sadly\"], [\"silently\"], [\"loudly\"],\n",
    "        [\"angrily\"], [\"eagerly\"], [\"most\"], [\"tonight\"], [\"lastly\"], [\"quite\"], [\"far\"]\n",
    "    ],\n",
    "    \"MD\": [[\"will\"], [\"can\"], [\"should\"], [\"would\"], [\"may\"], [\"might\"], [\"must\"]],\n",
    "    \"VBG\": [\n",
    "        [\"playing\"], [\"running\"], [\"watching\"], [\"painting\"], [\"calling\"], [\"helping\"], [\"working\"],\n",
    "        [\"riding\"], [\"moving\"], [\"jumping\"], [\"cooking\"], [\"fighting\"], [\"dreaming\"], [\"dancing\"],\n",
    "        [\"kissing\"], [\"planning\"], [\"visiting\"], [\"starting\"], [\"ending\"], [\"going\"], [\"eating\"],\n",
    "        [\"spending\"], [\"enjoying\"], [\"taking\"], [\"including\"], [\"preferring\"], [\"meeting\"]\n",
    "    ],\n",
    "    \"Wh_Word\": [\n",
    "        [\"what\"], [\"where\"], [\"when\"], [\"why\"], [\"how\"]\n",
    "    ],\n",
    "    \"JJ\": [\n",
    "        [\"red\"], [\"blue\"], [\"big\"], [\"small\"], [\"delicious\"], [\"beautiful\"], [\"interesting\"], [\"important\"],\n",
    "        [\"happy\"], [\"sad\"], [\"fast\"], [\"slow\"], [\"heavy\"], [\"light\"], [\"young\"], [\"old\"], [\"rich\"],\n",
    "        [\"poor\"], [\"strong\"], [\"weak\"], [\"friendly\"], [\"angry\"], [\"quiet\"], [\"loud\"], [\"clean\"], [\"dirty\"],\n",
    "        [\"long\"], [\"short\"], [\"thick\"], [\"thin\"], [\"hot\"], [\"cold\"], [\"warm\"], [\"cool\"], [\"soft\"], [\"hard\"],\n",
    "        [\"sharp\"], [\"smooth\"], [\"rough\"], [\"expensive\"], [\"cheap\"], [\"sweet\"], [\"sour\"], [\"bitter\"],\n",
    "        [\"spicy\"], [\"tall\"], [\"short\"], [\"early\"], [\"late\"], [\"kind\"], [\"generous\"], [\"selfish\"], [\"brave\"],\n",
    "        [\"breathtaking\"], [\"gorgeous\"], [\"active\"], [\"funny\"], [\"serious\"], [\"polite\"], [\"rude\"],\n",
    "        [\"creative\"], [\"boring\"], [\"beautiful\"], [\"ugly\"], [\"pleasant\"], [\"unpleasant\"], [\"calm\"],\n",
    "        [\"nervous\"], [\"historical\"], [\"national\"]\n",
    "    ],\n",
    "    \"AUX\": [[\"does\"], [\"did\"], [\"do\"], [\"am\"], [\"is\"], [\"are\"]],\n",
    "    \"Neg\": [[\"not\"]],\n",
    "    \"DO\": [[\"do\"]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    # \"book the flight through Houston\", #ok\n",
    "    # \"I bought a book\",#ok\n",
    "    # \"she enjoys the music\", #ok\n",
    "    # \"we want a meal\",#ok\n",
    "    # \"you watched a movie\",#ok\n",
    "    \"I was in the school\",#lack of [in]\n",
    "    \"I bought a present for my friend yesterday.\",#lack of [for, my]\n",
    "    \"I enjoy historical novels.\",#[historical]\n",
    "    \"I helped my mother with dinner yesterday.\",#[my, mother, dinner]\n",
    "    \"epics tell about our national culture and history.\",#[tell, about, our, national, culture, and, history]\n",
    "    \"watermelon is the most beautiful fruit of summer.\",#[watermelon, most, fruit, of, summer]\n",
    "    \"will you attend the meeting tonight?\",#[attend, meeting, tonight]\n",
    "    \"we watched the moonlight under this tree every night.\",#[moonlight, tree, every, night]\n",
    "    \"when did you come here lastly?\",#[lastly]\n",
    "    \"the school was quite far from our village.\",#[quite, far, our, village]\n",
    "    \"do not listen to loud music.\",#[listen, ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CKYParser:\n",
    "    def __init__(self, grammar):\n",
    "        \"\"\"\n",
    "        Initialize the CKY Parser.\n",
    "        \n",
    "        :param grammar: A dictionary where keys are non-terminals,\n",
    "                        and values are lists of possible right-hand side productions.\n",
    "        \"\"\"\n",
    "        self.grammar = grammar\n",
    "\n",
    "    def parse(self, sentence):\n",
    "        \"\"\"\n",
    "        Parses the input sentence using the CKY algorithm.\n",
    "        \n",
    "        :param sentence: Untokenized input sentence.\n",
    "        :return: Parse table (2D list) and backpointers for tree reconstruction.\n",
    "        \"\"\"\n",
    "        tokens = self._tokenize(sentence)  # Tokenize the sentence into words\n",
    "        n = len(tokens)\n",
    "        table = [[set() for _ in range(n + 1)] for _ in range(n)]  # CKY table\n",
    "        backpointers = [[{} for _ in range(n + 1)] for _ in range(n)]  # Backpointers for tree reconstruction\n",
    "\n",
    "        for j in range(1, n + 1):  # Loop over columns\n",
    "            word = tokens[j - 1]\n",
    "            found = False\n",
    "            for A, rhs_list in self.grammar.items():\n",
    "                for rhs in rhs_list:\n",
    "                    if len(rhs) == 1 and rhs[0] == word:  # Terminal match\n",
    "                        table[j - 1][j].add(A)\n",
    "                        self._expand_non_terminals(A, table, j - 1, j)  # Expand possible non-terminals\n",
    "                        found = True\n",
    "            if not found:\n",
    "                print(f\"The word: -{word}- is not in the lexicon.\")\n",
    "\n",
    "        # Fill the rest of the table\n",
    "        for span in range(2, n + 1):  # Loop over spans (row index difference)\n",
    "            for i in range(n - span + 1):  # Start of span (row index)\n",
    "                j = i + span  # End of span (column index)\n",
    "                for k in range(i + 1, j):  # Split point (midpoint)\n",
    "                    for A, rhs_list in self.grammar.items():\n",
    "                        for rhs in rhs_list:\n",
    "                            if len(rhs) == 2:  # Binary production\n",
    "                                B, C = rhs\n",
    "                                if B in table[i][k] and C in table[k][j]:  # Check grammar\n",
    "                                    table[i][j].add(A)\n",
    "                                    backpointers[i][j].setdefault(A, []).append((k, B, C))\n",
    "                                    self._expand_non_terminals(A, table, i, j)  # Expand possible non-terminals\n",
    "\n",
    "        return table, backpointers\n",
    "\n",
    "    def _expand_non_terminals(self, symbol, table, start, end):\n",
    "        \"\"\"\n",
    "        Expands non-terminals that can derive the given symbol and adds them to the table.\n",
    "        \n",
    "        :param symbol: The symbol to expand.\n",
    "        :param table: The CKY table.\n",
    "        :param start: Start index in the table.\n",
    "        :param end: End index in the table.\n",
    "        \"\"\"\n",
    "        for A, rhs_list in self.grammar.items():\n",
    "            for rhs in rhs_list:\n",
    "                if len(rhs) == 1 and rhs[0] == symbol:  # Unary production (A -> symbol)\n",
    "                    if A not in table[start][end]:\n",
    "                        table[start][end].add(A)\n",
    "                        self._expand_non_terminals(A, table, start, end)  # Recursive expansion\n",
    "\n",
    "    def _tokenize(self, sentence):\n",
    "        \"\"\"\n",
    "        Tokenizes an input sentence into words.\n",
    "        \n",
    "        :param sentence: Input sentence as a string.\n",
    "        :return: List of tokens.\n",
    "        \"\"\"\n",
    "        return re.findall(r'\\w+', sentence)\n",
    "\n",
    "    def extract_tree(self, backpointers, start, end, symbol):\n",
    "        \"\"\"\n",
    "        Recursively extracts the parse tree from backpointers.\n",
    "        \n",
    "        :param backpointers: Backpointers for the parse table.\n",
    "        :param start: Start index of the current span.\n",
    "        :param end: End index of the current span.\n",
    "        :param symbol: The current non-terminal symbol to expand.\n",
    "        :return: A nested tuple representing the parse tree.\n",
    "        \"\"\"\n",
    "        if end - start == 1:  # Terminal symbol (word span)\n",
    "            return symbol\n",
    "\n",
    "        if symbol not in backpointers[start][end]:\n",
    "            return None\n",
    "\n",
    "        for k, B, C in backpointers[start][end][symbol]:\n",
    "            left_tree = self.extract_tree(backpointers, start, k, B)\n",
    "            right_tree = self.extract_tree(backpointers, k, end, C)\n",
    "            return (symbol, left_tree, right_tree)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def print_table(self, table):\n",
    "        \"\"\"\n",
    "        Prints the parse table for debugging purposes, excluding the first column.\n",
    "        \n",
    "        :param table: The CKY parse table.\n",
    "        \"\"\"\n",
    "        for row in table:\n",
    "            print([\"{\" + \", \".join(cell) + \"}\" for cell in row[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:  I was in the school\n",
      "Parse Table:\n",
      "['{PRP, NP}', '{X2, S}', '{}', '{}', '{X2, S}']\n",
      "['{}', '{VBD, VP, S}', '{}', '{}', '{VP, S}']\n",
      "['{}', '{}', '{IN}', '{}', '{PP}']\n",
      "['{}', '{}', '{}', '{DT}', '{NP}']\n",
      "['{}', '{}', '{}', '{}', '{NN, Nominal}']\n",
      "Correct!!! \n",
      "\n",
      "Parse Tree:\n",
      "('S', 'NP', ('VP', 'VP', ('PP', 'IN', ('NP', 'DT', 'Nominal')))) \n",
      "\n",
      "The word: -my- is not in the lexicon.\n",
      "sentence:  I bought a present for my friend yesterday.\n",
      "Parse Table:\n",
      "['{PRP, NP}', '{X2, S}', '{}', '{X2, S}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{VBD, VP, S}', '{}', '{VP, S}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{DT}', '{NP}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{VP, VB, Nominal, VBP, NN, S}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{IN}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{NN, Nominal}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{RB}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "sentence:  I enjoy historical novels.\n",
      "Parse Table:\n",
      "['{PRP, NP}', '{X2, S}', '{}', '{}']\n",
      "['{}', '{VP, VBP, VB, S}', '{}', '{}']\n",
      "['{}', '{}', '{JJ}', '{Nominal}']\n",
      "['{}', '{}', '{}', '{NNS, Nominal}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "The word: -my- is not in the lexicon.\n",
      "sentence:  I helped my mother with dinner yesterday.\n",
      "Parse Table:\n",
      "['{PRP, NP}', '{X2, S}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{VBD, VP, S}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{NN, Nominal}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{IN}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{NN, Nominal}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{RB}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "The word: -epics- is not in the lexicon.\n",
      "The word: -about- is not in the lexicon.\n",
      "The word: -our- is not in the lexicon.\n",
      "The word: -and- is not in the lexicon.\n",
      "sentence:  epics tell about our national culture and history.\n",
      "Parse Table:\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{VP, VB, S}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{JJ}', '{Nominal}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{NN, Nominal}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{NN, Nominal}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "sentence:  watermelon is the most beautiful fruit of summer.\n",
      "Parse Table:\n",
      "['{NN, Nominal}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{AUX}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{DT}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{RB}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{JJ}', '{Nominal}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{NN, Nominal}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{IN}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{VP, VB, S}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "sentence:  will you attend the meeting tonight?\n",
      "Parse Table:\n",
      "['{MD}', '{X4}', '{S}', '{}', '{}', '{}']\n",
      "['{}', '{PRP, NP}', '{X2, S}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{VP, VB, S}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{DT}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{VBG}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{RB}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "The word: -every- is not in the lexicon.\n",
      "The word: -night- is not in the lexicon.\n",
      "sentence:  we watched the moonlight under this tree every night.\n",
      "Parse Table:\n",
      "['{PRP, NP}', '{X2, S}', '{}', '{X2, S}', '{}', '{}', '{X2, S}', '{}', '{}']\n",
      "['{}', '{VBD, VP, S}', '{}', '{VP, S}', '{}', '{}', '{VP, S}', '{}', '{}']\n",
      "['{}', '{}', '{DT}', '{NP}', '{}', '{}', '{NP}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{NN, Nominal}', '{}', '{}', '{Nominal}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{IN}', '{}', '{PP}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{DT}', '{NP}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{NN, Nominal}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "sentence:  when did you come here lastly?\n",
      "Parse Table:\n",
      "['{Wh_Word}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{AUX}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{PRP, NP}', '{X2, S}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{VP, VB, S}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{RB}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{RB}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "The word: -our- is not in the lexicon.\n",
      "sentence:  the school was quite far from our village.\n",
      "Parse Table:\n",
      "['{DT}', '{NP}', '{X2, S}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{NN, Nominal}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{VBD, VP, S}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{RB}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{RB}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{IN}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{}', '{}', '{NN, Nominal}']\n",
      "The sentence could not be parsed. \n",
      "\n",
      "sentence:  do not listen to loud music.\n",
      "Parse Table:\n",
      "['{AUX, DO}', '{X8, X5}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{Neg}', '{}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{NN, Nominal}', '{}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{IN}', '{}', '{}']\n",
      "['{}', '{}', '{}', '{}', '{JJ}', '{Nominal}']\n",
      "['{}', '{}', '{}', '{}', '{}', '{NN, Nominal}']\n",
      "The sentence could not be parsed. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = CKYParser(grammar_rules_chomsky)\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    table, backpointers = parser.parse(sentence)\n",
    "    print('sentence: ', sentence)\n",
    "    # Print Table\n",
    "    print(\"Parse Table:\")\n",
    "    parser.print_table(table)\n",
    "\n",
    "    # Extract Parse Tree\n",
    "    start_symbol = \"S\"\n",
    "    tokens = parser._tokenize(sentence)\n",
    "    n = len(tokens)\n",
    "    if start_symbol in table[0][n]:\n",
    "        print('Correct!!! ')\n",
    "        print(\"\\nParse Tree:\")\n",
    "        tree = parser.extract_tree(backpointers, 0, n, start_symbol)\n",
    "        print(tree, \"\\n\")\n",
    "    else:\n",
    "        print(\"The sentence could not be parsed. \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
